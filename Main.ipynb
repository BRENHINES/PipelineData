{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# <u>This is our Mini project for the course \"Fundamental Data Concepts\" (4DACF) at SUPINFO Lyon :</u>\n",
    "\n",
    "## <u>Evaluation Project - Data Processing and Visualization :</u>\n",
    "\n",
    "## <u>Project Objective :</u>\n",
    "You will design a complete data processing pipeline that includes several key steps: anonymization, transformation, cleaning, and data visualization.\n",
    "\n",
    "\n",
    "The goal is to leverage multiple technologies to produce a high-quality pipeline that adheres to best practices.\n",
    "\n",
    "This project must be carried out in groups of up to three students.\n",
    "\n",
    "## <u>Contexte :</u>\n",
    "A fictional e-commerce company aims to leverage its customer and transaction data while complying with GDPR regulations.\n",
    "\n",
    "The company has a dataset containing sensitive information and seeks to obtain:\n",
    "\n",
    "- [ ] An automated pipeline for anonymizing, transforming, and cleaning the data in python.\n",
    "- [ ] A final output optimized for direct use in Power BI.\n",
    "\n",
    "## <u>BONUS :</u>\n",
    "\n",
    "- [ ] A set of visualizations in Python that provide insights into the data."
   ],
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# <u>Step 1:</u> Pipeline Preparation: Python code for anonymization, cleaning, and transformation",
   "id": "497a74daa0aa671d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T10:41:46.673902Z",
     "start_time": "2025-02-19T10:41:46.668288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Importing the necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re"
   ],
   "id": "324f03d0f7486edc",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Exploratory Data Analysis (EDA)\n",
    "\n",
    "The first step in any data processing pipeline is to understand the data. This involves exploring the data to identify patterns, trends, and potential issues. EDA is a critical step that helps data engineer understand the data and make informed decisions about how to process it."
   ],
   "id": "7261471387cd8c79"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T10:41:46.706762Z",
     "start_time": "2025-02-19T10:41:46.687229Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the dataset : Mini_Projet_Evaluation.csv\n",
    "\n",
    "dataset_file_path: str = 'data/raw/Mini_Projet_Evaluation.csv'\n",
    "dataset = pd.read_csv(dataset_file_path)"
   ],
   "id": "2c6a95f4da68885d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T10:41:46.721894Z",
     "start_time": "2025-02-19T10:41:46.712101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Explore the data : Structure of the data, data types, etc.\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "\n",
    "print(f\"The dataset head is : \\n {dataset.head()}\") #to see a quick view of the dataset"
   ],
   "id": "f385c12f1c057b3f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset head is : \n",
      "                                ClientID       Nom       Pr√©nom  \\\n",
      "0  d34f9cab-5d14-469f-aa80-c0146f3b93c7   Walters  Christopher   \n",
      "1  d9b374f9-8cec-4ae7-9137-c1d930d0aae0    Weaver        Linda   \n",
      "2  72855e63-d98e-42e9-a10f-d9e4fac6e82f  Odonnell        Julie   \n",
      "3  3fcb2796-9692-4fcf-affb-0100d9a74ae1     Clark      Charles   \n",
      "4  50b21cc8-6f68-45c5-9b75-335ef55b41b2  Martinez        David   \n",
      "\n",
      "                       Email              T√©l√©phone  \\\n",
      "0       vickie68@hotmail.com     818-767-2351x61325   \n",
      "1    mackrenee@rodriguez.com      892-112-2129x2425   \n",
      "2         alexis55@gmail.com  001-505-122-4709x1134   \n",
      "3  jenniferschmidt@yahoo.com          (101)867-7119   \n",
      "4     hmiddleton@mendoza.com     (820)441-6404x9218   \n",
      "\n",
      "                                             Adresse          Ville  \\\n",
      "0                   Unit 4018 Box 5177, DPO AA 69318      Lauratown   \n",
      "1           19114 Ryan Grove, East Miranda, MO 40887    Herreraview   \n",
      "2           610 Donna Neck, Lake Paulmouth, MA 32585  Lake Erictown   \n",
      "3               177 Anne Bridge, Perezberg, MA 91533  New Andrewton   \n",
      "4  59971 Haynes Glens Apt. 520, Meganhaven, MN 92380  Rodriguezport   \n",
      "\n",
      "   CodePostal                 Pays DateNaissance  ...  \\\n",
      "0       45532  Antigua and Barbuda    1996-09-15  ...   \n",
      "1        6486               Belize    2000-01-11  ...   \n",
      "2       85092              Andorra    1961-06-07  ...   \n",
      "3       87164                Samoa    1970-11-19  ...   \n",
      "4       53640         Burkina Faso    1946-02-26  ...   \n",
      "\n",
      "   Cat√©gorieProduitPr√©f√©r√© Fr√©quenceAchatMensuel  PanierMoyen ScoreFid√©lit√©  \\\n",
      "0                    Sport                     6       165.43            85   \n",
      "1             √âlectronique                     6        71.01            15   \n",
      "2             Alimentation                     9       104.43            10   \n",
      "3             Alimentation                     5       161.23             4   \n",
      "4                     Mode                     1        87.27             6   \n",
      "\n",
      "  NombreRemboursements  MontantTotalRembours√© AvisClient  \\\n",
      "0                    1                  11.68     Neutre   \n",
      "1                    2                 152.13  Satisfait   \n",
      "2                    5                 342.60  Satisfait   \n",
      "3                    0                   0.00  M√©content   \n",
      "4                    0                   0.00  M√©content   \n",
      "\n",
      "   AbonnementNewsletter  TypePaiementFavori StatutCompte  \n",
      "0                  True              Paypal      Inactif  \n",
      "1                 False      Carte bancaire        Actif  \n",
      "2                 False       Cryptomonnaie     Suspendu  \n",
      "3                 False            Virement        Actif  \n",
      "4                  True       Cryptomonnaie      Inactif  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T10:41:46.740283Z",
     "start_time": "2025-02-19T10:41:46.729175Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Display the infos of the dataset\n",
    "\n",
    "print(f\"The dataset info is : \\n {dataset.info()}\") #to see the structure of the dataset"
   ],
   "id": "7b92923c35a5f7c7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 31 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   ClientID                 1000 non-null   object \n",
      " 1   Nom                      1000 non-null   object \n",
      " 2   Pr√©nom                   1000 non-null   object \n",
      " 3   Email                    1000 non-null   object \n",
      " 4   T√©l√©phone                1000 non-null   object \n",
      " 5   Adresse                  1000 non-null   object \n",
      " 6   Ville                    1000 non-null   object \n",
      " 7   CodePostal               1000 non-null   int64  \n",
      " 8   Pays                     1000 non-null   object \n",
      " 9   DateNaissance            1000 non-null   object \n",
      " 10  √Çge                      1000 non-null   int64  \n",
      " 11  Sexe                     1000 non-null   object \n",
      " 12  Num√©roCarteCr√©dit        1000 non-null   int64  \n",
      " 13  TypeCarteCr√©dit          1000 non-null   object \n",
      " 14  DateExpirationCarte      1000 non-null   object \n",
      " 15  SoldeCompte              1000 non-null   float64\n",
      " 16  TypeClient               1000 non-null   object \n",
      " 17  NombreAchats             1000 non-null   int64  \n",
      " 18  MontantTotalAchats       1000 non-null   float64\n",
      " 19  DernierAchat             1000 non-null   object \n",
      " 20  ProduitPr√©f√©r√©           1000 non-null   object \n",
      " 21  Cat√©gorieProduitPr√©f√©r√©  1000 non-null   object \n",
      " 22  Fr√©quenceAchatMensuel    1000 non-null   int64  \n",
      " 23  PanierMoyen              1000 non-null   float64\n",
      " 24  ScoreFid√©lit√©            1000 non-null   int64  \n",
      " 25  NombreRemboursements     1000 non-null   int64  \n",
      " 26  MontantTotalRembours√©    1000 non-null   float64\n",
      " 27  AvisClient               1000 non-null   object \n",
      " 28  AbonnementNewsletter     1000 non-null   bool   \n",
      " 29  TypePaiementFavori       1000 non-null   object \n",
      " 30  StatutCompte             1000 non-null   object \n",
      "dtypes: bool(1), float64(4), int64(7), object(19)\n",
      "memory usage: 235.5+ KB\n",
      "The dataset info is : \n",
      " None\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T10:41:46.751530Z",
     "start_time": "2025-02-19T10:41:46.749140Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Display the shape of the dataset\n",
    "\n",
    "print(f\"This dataset have {dataset.shape[0]} entries and {dataset.shape[1]} columns.\") #to see the number of rows and columns in resume, and to see the eventual problems on the dataset"
   ],
   "id": "24103c662aa52a6e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset have 1000 entries and 31 columns.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T10:41:46.779427Z",
     "start_time": "2025-02-19T10:41:46.768937Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Display the descriptive statistics of the dataset\n",
    "\n",
    "print(f\"The dataset describe is : \\n {dataset.describe()}\") #to see the statistical summary of the dataset, to see the eventual problems on the dataset (outliers, etc.)"
   ],
   "id": "63ac21133446afed",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset describe is : \n",
      "          CodePostal          √Çge  Num√©roCarteCr√©dit  SoldeCompte  \\\n",
      "count   1000.000000  1000.000000       1.000000e+03  1000.000000   \n",
      "mean   50576.295000    55.466000       3.992066e+17  2619.975090   \n",
      "std    29093.854764    21.021816       1.288862e+18  1443.421728   \n",
      "min      525.000000    18.000000       6.042067e+10     2.680000   \n",
      "25%    23961.250000    37.000000       1.800195e+14  1385.430000   \n",
      "50%    52513.000000    56.000000       3.505393e+15  2734.705000   \n",
      "75%    76447.000000    73.000000       4.610821e+15  3865.872500   \n",
      "max    99876.000000    91.000000       4.998787e+18  4994.880000   \n",
      "\n",
      "       NombreAchats  MontantTotalAchats  Fr√©quenceAchatMensuel  PanierMoyen  \\\n",
      "count   1000.000000          1000.00000            1000.000000  1000.000000   \n",
      "mean      10.487000          2608.90697               4.879000   238.349630   \n",
      "std        5.890036          2287.38721               3.260213   150.407597   \n",
      "min        0.000000             0.00000               0.000000     0.000000   \n",
      "25%        6.000000           780.31750               2.000000   105.547500   \n",
      "50%       11.000000          1877.64000               5.000000   235.540000   \n",
      "75%       16.000000          4011.89750               8.000000   370.295000   \n",
      "max       20.000000          9752.86000              10.000000   499.830000   \n",
      "\n",
      "       ScoreFid√©lit√©  NombreRemboursements  MontantTotalRembours√©  \n",
      "count    1000.000000           1000.000000             1000.00000  \n",
      "mean       51.484000              2.570000              262.85884  \n",
      "std        28.691583              1.705875              248.75859  \n",
      "min         0.000000              0.000000                0.00000  \n",
      "25%        27.000000              1.000000               50.26500  \n",
      "50%        52.000000              3.000000              192.24000  \n",
      "75%        76.000000              4.000000              394.25250  \n",
      "max       100.000000              5.000000              995.98000  \n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T10:41:46.797734Z",
     "start_time": "2025-02-19T10:41:46.789945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Display the data types in the dataset\n",
    "\n",
    "print(f\"The dataset data types are : \\n {dataset.dtypes}\") #to see the data types of the dataset"
   ],
   "id": "f2ae2e4ffb539d28",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset data types are : \n",
      " ClientID                    object\n",
      "Nom                         object\n",
      "Pr√©nom                      object\n",
      "Email                       object\n",
      "T√©l√©phone                   object\n",
      "Adresse                     object\n",
      "Ville                       object\n",
      "CodePostal                   int64\n",
      "Pays                        object\n",
      "DateNaissance               object\n",
      "√Çge                          int64\n",
      "Sexe                        object\n",
      "Num√©roCarteCr√©dit            int64\n",
      "TypeCarteCr√©dit             object\n",
      "DateExpirationCarte         object\n",
      "SoldeCompte                float64\n",
      "TypeClient                  object\n",
      "NombreAchats                 int64\n",
      "MontantTotalAchats         float64\n",
      "DernierAchat                object\n",
      "ProduitPr√©f√©r√©              object\n",
      "Cat√©gorieProduitPr√©f√©r√©     object\n",
      "Fr√©quenceAchatMensuel        int64\n",
      "PanierMoyen                float64\n",
      "ScoreFid√©lit√©                int64\n",
      "NombreRemboursements         int64\n",
      "MontantTotalRembours√©      float64\n",
      "AvisClient                  object\n",
      "AbonnementNewsletter          bool\n",
      "TypePaiementFavori          object\n",
      "StatutCompte                object\n",
      "dtype: object\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Data Cleaning\n",
    "\n",
    "Data cleaning is the process of identifying and correcting errors in the data. This step is essential for ensuring the quality of the data and the accuracy of the analysis. Data cleaning involves several key tasks, including:\n",
    "- [X] Handling missing values\n",
    "- [X] Removing duplicates\n",
    "- [X] Correcting errors\n",
    "- [X] Standardizing data\n",
    "- [ ] Handling outliers\n",
    "- [ ] Encoding categorical variables\n",
    "- [ ] Feature engineering\n",
    "- [ ] Handling skewed data\n",
    "- [ ] Handling time series data\n",
    "- [ ] Standardizing data types\n"
   ],
   "id": "2e2f061bfb760744"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T10:41:46.816042Z",
     "start_time": "2025-02-19T10:41:46.811870Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Data Cleaning : Cleaning the dataset\n",
    "\n",
    "# Handling missing values\n",
    "\n",
    "missing_values_count = dataset.isnull().sum()\n",
    "print(f\"The missing values count is : \\n {missing_values_count}\") #to see the number of missing values in each column of the dataset"
   ],
   "id": "52d4bbd49a9c8d51",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The missing values count is : \n",
      " ClientID                   0\n",
      "Nom                        0\n",
      "Pr√©nom                     0\n",
      "Email                      0\n",
      "T√©l√©phone                  0\n",
      "Adresse                    0\n",
      "Ville                      0\n",
      "CodePostal                 0\n",
      "Pays                       0\n",
      "DateNaissance              0\n",
      "√Çge                        0\n",
      "Sexe                       0\n",
      "Num√©roCarteCr√©dit          0\n",
      "TypeCarteCr√©dit            0\n",
      "DateExpirationCarte        0\n",
      "SoldeCompte                0\n",
      "TypeClient                 0\n",
      "NombreAchats               0\n",
      "MontantTotalAchats         0\n",
      "DernierAchat               0\n",
      "ProduitPr√©f√©r√©             0\n",
      "Cat√©gorieProduitPr√©f√©r√©    0\n",
      "Fr√©quenceAchatMensuel      0\n",
      "PanierMoyen                0\n",
      "ScoreFid√©lit√©              0\n",
      "NombreRemboursements       0\n",
      "MontantTotalRembours√©      0\n",
      "AvisClient                 0\n",
      "AbonnementNewsletter       0\n",
      "TypePaiementFavori         0\n",
      "StatutCompte               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T10:41:46.837890Z",
     "start_time": "2025-02-19T10:41:46.832224Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Removing duplicates\n",
    "\n",
    "duplicates_values_count = dataset.duplicated().sum()\n",
    "print(f\"The number of duplicates in the dataset is : {duplicates_values_count}\") #to see the number of duplicates in the dataset"
   ],
   "id": "67896144ccc3232e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of duplicates in the dataset is : 0\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T10:41:46.851164Z",
     "start_time": "2025-02-19T10:41:46.844570Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Correcting errors\n",
    "\n",
    "columns_to_verify = ['Sexe', 'Cat√©gorieProduitPr√©f√©r√©', 'AvisClient', 'AbonnementNewsletter', 'TypePaiementFavori', 'StatutCompte'] #to see the columns that we want to verify\n",
    "\n",
    "for col in columns_to_verify:\n",
    "    print(f\"\\nüîπ {col} : {dataset[col].nunique()} unique values\") #to see the number of unique values in each column of the dataset\n",
    "    print(dataset[col].unique())  # to see the unique values in each column of the dataset"
   ],
   "id": "cfcaac8ddeb35178",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Sexe : 2 unique values\n",
      "['M' 'F']\n",
      "\n",
      "üîπ Cat√©gorieProduitPr√©f√©r√© : 5 unique values\n",
      "['Sport' '√âlectronique' 'Alimentation' 'Mode' 'Maison']\n",
      "\n",
      "üîπ AvisClient : 5 unique values\n",
      "['Neutre' 'Satisfait' 'M√©content' 'Tr√®s m√©content' 'Tr√®s satisfait']\n",
      "\n",
      "üîπ AbonnementNewsletter : 2 unique values\n",
      "[ True False]\n",
      "\n",
      "üîπ TypePaiementFavori : 4 unique values\n",
      "['Paypal' 'Carte bancaire' 'Cryptomonnaie' 'Virement']\n",
      "\n",
      "üîπ StatutCompte : 3 unique values\n",
      "['Inactif' 'Actif' 'Suspendu']\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T13:05:24.018311Z",
     "start_time": "2025-02-19T13:05:23.969311Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Standardizing data\n",
    "\n",
    "# Standardizing the float columns\n",
    "columns_to_round = ['MontantTotalAchats', 'SoldeCompte', 'PanierMoyen', 'MontantTotalRembours√©'] #to see the columns that we want to round\n",
    "\n",
    "for col in columns_to_round:\n",
    "    dataset[col] = dataset[col].apply(lambda x: round(x, 2)) #to round the values in each column of the dataset\n",
    "\n",
    "# Standardizing the countries and cities columns\n",
    "standardize_name_columns = ['Pays', 'Ville'] #to see the columns that we want to standardize\n",
    "for col in standardize_name_columns:\n",
    "    dataset[col] = dataset[col].str.title() #to standardize the values in each column of the dataset\n",
    "\n",
    "# Standardizing the date columns\n",
    "standardize_date_columns = ['DateNaissance', 'DernierAchat'] #to see the columns that we want to standardize\n",
    "def standardise_date(date):\n",
    "    date = str(date).strip()\n",
    "    match = re.match(r\"^(\\d{4})-(\\d{2})-(\\d{2})$\", date)\n",
    "    if match:\n",
    "        return f\"{match.group(3)}/{match.group(2)}/{match.group(1)}\"  # JJ/MM/AAAA\n",
    "    return date\n",
    "\n",
    "for col in standardize_date_columns:\n",
    "    dataset[col] = dataset[col].apply(standardise_date) #to standardize the values in each column of the dataset"
   ],
   "id": "2d0ae65127993e39",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                ClientID        Nom       Pr√©nom  \\\n",
      "0   d34f9cab-5d14-469f-aa80-c0146f3b93c7    Walters  Christopher   \n",
      "1   d9b374f9-8cec-4ae7-9137-c1d930d0aae0     Weaver        Linda   \n",
      "2   72855e63-d98e-42e9-a10f-d9e4fac6e82f   Odonnell        Julie   \n",
      "3   3fcb2796-9692-4fcf-affb-0100d9a74ae1      Clark      Charles   \n",
      "4   50b21cc8-6f68-45c5-9b75-335ef55b41b2   Martinez        David   \n",
      "5   1149c70b-e75d-4398-a784-ff40152810db      Black      Stephen   \n",
      "6   20dea61b-c087-482c-9a71-2def299ed020    Spencer       Alexis   \n",
      "7   3faa9f83-0a50-4657-96cc-401944b5708c      Baker      Stephen   \n",
      "8   cd0594c6-c289-4fd6-92ad-495772743f5a   Williams      Timothy   \n",
      "9   6bed1a9f-2ee0-402e-8907-9fad020e36f7  Macdonald        Kevin   \n",
      "10  0c2cab59-6989-4832-aa97-84c398e67a5d       Haas       Rhonda   \n",
      "11  79eb32ae-12ca-4009-b8ec-b558d039caf8      Gould     Jennifer   \n",
      "12  073fdfca-a8df-4e28-ae42-460761586770     Martin      Tiffany   \n",
      "13  ae2fe7cd-0387-4e2b-abb6-9e6bce679b74       Webb        Frank   \n",
      "14  88dcb53d-58ba-4746-b942-91d07190a03c  Fernandez       Calvin   \n",
      "15  ad388d2e-a57a-4a60-b1d1-4fd15d27b74c      Cooke      Caitlin   \n",
      "16  1eedf4f2-9789-46f7-84ea-4329dc9ea314      Kelly        Robin   \n",
      "17  ef5c5f75-5404-4191-800f-a2bc3dac7412   Marshall      Jeffrey   \n",
      "18  8ff58ece-b7ce-49fc-871d-be7f8ce6153b   Santiago       Tracey   \n",
      "19  4d9c9411-36aa-473d-8fee-308a0442f836   Johnston      Brandon   \n",
      "\n",
      "                        Email               T√©l√©phone  \\\n",
      "0        vickie68@hotmail.com      818-767-2351x61325   \n",
      "1     mackrenee@rodriguez.com       892-112-2129x2425   \n",
      "2          alexis55@gmail.com   001-505-122-4709x1134   \n",
      "3   jenniferschmidt@yahoo.com           (101)867-7119   \n",
      "4      hmiddleton@mendoza.com      (820)441-6404x9218   \n",
      "5     greenemakayla@yahoo.com  001-241-995-6354x33199   \n",
      "6       robertsimon@gmail.com   001-213-157-9454x1584   \n",
      "7            sjames@gmail.com              2057671275   \n",
      "8     simonjonathan@gmail.com       (046)512-6303x860   \n",
      "9        paulpowell@smith.com        008-549-9685x489   \n",
      "10       shellywu@hotmail.com        901-546-7054x875   \n",
      "11   williamburgess@yahoo.com           (605)397-7437   \n",
      "12        tammy92@hotmail.com        123-725-6964x336   \n",
      "13     toddcrawford@gmail.com   001-094-151-6161x1656   \n",
      "14         scotttom@white.com           (410)400-3404   \n",
      "15  riddlelindsay@hotmail.com              3379093229   \n",
      "16          brenda37@long.com       872.173.4183x7125   \n",
      "17          wwright@gmail.com              4698822678   \n",
      "18         angela41@gmail.com            297-608-9379   \n",
      "19          ibenson@yahoo.com      176.380.0735x62459   \n",
      "\n",
      "                                              Adresse               Ville  \\\n",
      "0                    Unit 4018 Box 5177, DPO AA 69318           Lauratown   \n",
      "1            19114 Ryan Grove, East Miranda, MO 40887         Herreraview   \n",
      "2            610 Donna Neck, Lake Paulmouth, MA 32585       Lake Erictown   \n",
      "3                177 Anne Bridge, Perezberg, MA 91533       New Andrewton   \n",
      "4   59971 Haynes Glens Apt. 520, Meganhaven, MN 92380       Rodriguezport   \n",
      "5   70389 Richard Glen Apt. 625, Port Justinshire,...            Tarafurt   \n",
      "6   29242 Humphrey Squares, West Ericamouth, ID 30989          Smithhaven   \n",
      "7                    Unit 3338 Box 9454, DPO AE 48742        West Michael   \n",
      "8             1762 Wilcox Burg, Kennedystad, MI 28020         Bondborough   \n",
      "9        553 Steven Avenue, New Gabrielberg, SC 41397       Carpentertown   \n",
      "10  5226 Timothy Cove Suite 532, Danielburgh, DC 4...    North Randyhaven   \n",
      "11           724 Daniel Brooks, North Jason, MO 64838           Pughville   \n",
      "12   269 Meyer Square Apt. 570, Martinburgh, LA 13683          West Craig   \n",
      "13          1523 Wood Drive, Port Johnburgh, GA 71291      Suzannechester   \n",
      "14            921 Deborah Falls, Stevenfort, MT 76185         Rodneyshire   \n",
      "15  279 Montgomery Causeway Suite 115, Ramirezfort...            Whiteton   \n",
      "16  9701 Gutierrez Route Apt. 518, New Lance, OK 9...         Nicoleburgh   \n",
      "17  2469 Thomas Junctions Suite 075, Port Margaret...  Lake Courtneyville   \n",
      "18       0507 Williams Plains, South Steven, HI 98808        Michaelhaven   \n",
      "19     132 Lester Park Apt. 051, Martinview, NV 41514       North Deborah   \n",
      "\n",
      "    CodePostal                               Pays DateNaissance  ...  \\\n",
      "0        45532                Antigua And Barbuda    15/09/1996  ...   \n",
      "1         6486                             Belize    11/01/2000  ...   \n",
      "2        85092                            Andorra    07/06/1961  ...   \n",
      "3        87164                              Samoa    19/11/1970  ...   \n",
      "4        53640                       Burkina Faso    26/02/1946  ...   \n",
      "5        16900                         San Marino    11/04/1941  ...   \n",
      "6        50362                             Angola    22/11/1984  ...   \n",
      "7         2732                             Norway    26/04/1977  ...   \n",
      "8        63792                          Hong Kong    23/01/1949  ...   \n",
      "9        73481                               Mali    20/09/1940  ...   \n",
      "10       77860  Heard Island And Mcdonald Islands    13/04/1972  ...   \n",
      "11       25709                          Guatemala    22/02/2001  ...   \n",
      "12       11743               Syrian Arab Republic    28/12/1934  ...   \n",
      "13        6798                       Saudi Arabia    09/11/1942  ...   \n",
      "14       10897                              India    26/09/1992  ...   \n",
      "15       30256                        Philippines    02/02/1971  ...   \n",
      "16       16583                           Tanzania    03/07/1958  ...   \n",
      "17       52789                   Saint Barthelemy    12/05/1943  ...   \n",
      "18       63558                            Estonia    28/10/1959  ...   \n",
      "19        6684                              Korea    30/12/1999  ...   \n",
      "\n",
      "    Cat√©gorieProduitPr√©f√©r√© Fr√©quenceAchatMensuel  PanierMoyen ScoreFid√©lit√©  \\\n",
      "0                     Sport                     6       165.43            85   \n",
      "1              √âlectronique                     6        71.01            15   \n",
      "2              Alimentation                     9       104.43            10   \n",
      "3              Alimentation                     5       161.23             4   \n",
      "4                      Mode                     1        87.27             6   \n",
      "5              √âlectronique                     0       379.82            74   \n",
      "6              Alimentation                     2        18.39            40   \n",
      "7              Alimentation                     0        34.74            37   \n",
      "8                    Maison                     5       396.96            20   \n",
      "9                      Mode                     2        68.74            15   \n",
      "10                     Mode                     1       333.95            47   \n",
      "11                    Sport                     2       499.05            55   \n",
      "12                   Maison                     0       174.48            27   \n",
      "13                     Mode                     3       385.85             4   \n",
      "14             Alimentation                     8       189.50            23   \n",
      "15                   Maison                    10        40.50            59   \n",
      "16             √âlectronique                     0         0.00            10   \n",
      "17                    Sport                     8       340.39            93   \n",
      "18                     Mode                     0       143.89            10   \n",
      "19                    Sport                     1        18.95            47   \n",
      "\n",
      "   NombreRemboursements  MontantTotalRembours√©      AvisClient  \\\n",
      "0                     1                  11.68          Neutre   \n",
      "1                     2                 152.13       Satisfait   \n",
      "2                     5                 342.60       Satisfait   \n",
      "3                     0                   0.00       M√©content   \n",
      "4                     0                   0.00       M√©content   \n",
      "5                     2                 127.06       M√©content   \n",
      "6                     1                 129.76  Tr√®s m√©content   \n",
      "7                     2                  50.33       M√©content   \n",
      "8                     3                 485.85          Neutre   \n",
      "9                     2                 305.03       Satisfait   \n",
      "10                    1                  85.98          Neutre   \n",
      "11                    4                 262.75  Tr√®s m√©content   \n",
      "12                    4                 152.13  Tr√®s satisfait   \n",
      "13                    3                 426.82  Tr√®s m√©content   \n",
      "14                    3                  61.77  Tr√®s satisfait   \n",
      "15                    1                  70.21  Tr√®s m√©content   \n",
      "16                    1                  92.94          Neutre   \n",
      "17                    4                 557.23       Satisfait   \n",
      "18                    0                   0.00       M√©content   \n",
      "19                    4                 171.28       M√©content   \n",
      "\n",
      "    AbonnementNewsletter  TypePaiementFavori StatutCompte  \n",
      "0                   True              Paypal      Inactif  \n",
      "1                  False      Carte bancaire        Actif  \n",
      "2                  False       Cryptomonnaie     Suspendu  \n",
      "3                  False            Virement        Actif  \n",
      "4                   True       Cryptomonnaie      Inactif  \n",
      "5                  False            Virement     Suspendu  \n",
      "6                   True      Carte bancaire      Inactif  \n",
      "7                   True            Virement      Inactif  \n",
      "8                   True              Paypal        Actif  \n",
      "9                   True              Paypal      Inactif  \n",
      "10                  True      Carte bancaire        Actif  \n",
      "11                  True            Virement        Actif  \n",
      "12                  True              Paypal      Inactif  \n",
      "13                  True              Paypal        Actif  \n",
      "14                 False       Cryptomonnaie        Actif  \n",
      "15                  True       Cryptomonnaie      Inactif  \n",
      "16                 False            Virement        Actif  \n",
      "17                 False            Virement     Suspendu  \n",
      "18                  True              Paypal     Suspendu  \n",
      "19                  True      Carte bancaire        Actif  \n",
      "\n",
      "[20 rows x 31 columns]\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Data Transformation (Anonymization, pseudonomization, columns selection)\n",
    "Data transformation is the process of converting raw data into a format that is suitable for analysis. This step involves several key tasks, including:\n",
    "- [ ] Anonymization\n",
    "- [ ] Pseudonymization\n",
    "- [ ] Aggregation\n",
    "- [ ] Encoding\n",
    "- [ ] Data discretization\n",
    "- [ ] Data imputation\n",
    "- [ ] Data integration\n",
    "- [ ] Data reduction\n",
    "- [ ] Data wrangling\n",
    "- [ ] Data munging\n",
    "- [ ] Data fusion\n",
    "- [ ] Data harmonization"
   ],
   "id": "ce79e579e4a2500d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T10:41:46.879213Z",
     "start_time": "2025-02-19T10:41:46.877439Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "f45d8161d8edf1a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Validation\n",
    "Data validation is the process of ensuring that the data is accurate, complete, and consistent. This step involves several key tasks, including:\n",
    "- [ ] Data profiling\n",
    "- [ ] Data quality assessment\n",
    "- [ ] Data integrity checks\n",
    "- [ ] Data validation rules\n",
    "- [ ] Data validation checks\n",
    "- [ ] Data validation methods\n",
    "- [ ] Data validation techniques\n",
    "- [ ] Data validation tools"
   ],
   "id": "cd16d3b57713f8e6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T10:41:46.891273Z",
     "start_time": "2025-02-19T10:41:46.888759Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "fbc121e30a2defb3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. Data Export (To CSV or Excel)\n",
    "The final step in the data processing pipeline is to export the cleaned and transformed data to a file format that can be used for analysis. This step involves exporting the data to a CSV or Excel file, which can then be imported into a data visualization tool for further analysis."
   ],
   "id": "6f1e70ade75cca53"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T10:41:46.903921Z",
     "start_time": "2025-02-19T10:41:46.901832Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "eb6212e08230c2dc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 6. Data Visualization (BONUS)\n",
    "\n",
    "Data visualization is the process of representing data graphically to help data engineers and analysts understand the data and identify patterns and trends. Data visualization is a critical step in the data processing pipeline, as it helps to communicate the results of the analysis to stakeholders and decision-makers. Data visualization involves several key tasks, including:"
   ],
   "id": "a4cd9097658b2132"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T10:41:46.917599Z",
     "start_time": "2025-02-19T10:41:46.916388Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "4545d3c19f1e3a86",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
